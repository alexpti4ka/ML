{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u6LW_I1yvaTl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadnIgZUvkJB"
      },
      "source": [
        "# 1. Анализ и очистка датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wck4wcfpvezh",
        "outputId": "214c2062-e946-4bd3-9621-6a5ce72f4983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alexattia/the-simpsons-characters-dataset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading the-simpsons-characters-dataset.zip to /content\n",
            " 99% 1.07G/1.08G [00:08<00:00, 69.6MB/s]\n",
            "100% 1.08G/1.08G [00:08<00:00, 134MB/s] \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d alexattia/the-simpsons-characters-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rHOdsrZavz7G"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('the-simpsons-characters-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYJXtFUli1RI",
        "outputId": "5b0acf2e-40ad-4754-886d-fddb0c43ddff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Unnamed: 0                      name  total  train  test  bounding_box\n",
            "0            0             Homer Simpson   2246   1909   337           612\n",
            "1            1              Ned Flanders   1454   1236   218           595\n",
            "2            2               Moe Szyslak   1452   1234   218           215\n",
            "3            3              Lisa Simpson   1354   1151   203           562\n",
            "4            4              Bart Simpson   1342   1141   201           554\n",
            "5            5             Marge Simpson   1291   1097   194           557\n",
            "6            6          Krusty The Clown   1206   1025   181           226\n",
            "7            7         Principal Skinner   1194   1015   179           506\n",
            "8            8  Charles Montgomery Burns   1193   1014   179           650\n",
            "9            9       Milhouse Van Houten   1079    917   162           210\n",
            "10          10              Chief Wiggum    986    838   148           209\n",
            "11          11    Abraham Grampa Simpson    913    776   137           595\n",
            "12          12              Sideshow Bob    877    745   132           203\n",
            "13          13    Apu Nahasapeemapetilon    623    530    93           206\n",
            "14          14             Kent Brockman    498    423    75           213\n",
            "15          15            Comic Book Guy    469    399    70           208\n",
            "16          16            Edna Krabappel    457    388    69           212\n",
            "17          17              Nelson Muntz    358    304    54           219\n",
            "18          18             Lenny Leonard    310    264    46             0\n",
            "19          19              Mayor Quimby    246    209    37             0\n",
            "20          20           Waylon Smithers    181    154    27             0\n",
            "21          21            Maggie Simpson    128    109    19             0\n",
            "22          22      Groundskeeper Willie    121    103    18             0\n",
            "23          23             Barney Gumble    106     90    16             0\n",
            "24          24             Selma Bouvier    103     88    15             0\n",
            "25          25              Carl Carlson     98     83    15             0\n",
            "26          26              Ralph Wiggum     89     76    13             0\n",
            "27          27             Patty Bouvier     72     61    11             0\n",
            "28          28             Martin Prince     71     60    11             0\n",
            "29          29      Professor John Frink     65     55    10             0\n",
            "30          30            Snake Jailbird     55     47     8             0\n",
            "31          31           Cletus Spuckler     47     40     7             0\n",
            "32          32        Rainier Wolfcastle     45     38     7             0\n",
            "33          33             Agnes Skinner     42     36     6             0\n",
            "34          34              Sideshow Mel     40     34     6             0\n",
            "35          35                 Otto Mann     32     27     5             0\n",
            "36          36                  Fat Tony     27     23     4             0\n",
            "37          37                       Gil     27     23     4             0\n",
            "38          38               Miss Hoover     17     14     3             0\n",
            "39          39                 Disco Stu      8      7     1             0\n",
            "40          40              Troy Mcclure      8      7     1             0\n",
            "41          41               Lionel Hutz      3      3     0             0\n",
            "42          42               Jimbo Jones      0      0     0             0\n",
            "43          43             Bumblebee Man      0      0     0             0\n",
            "44          44              Hans Moleman      0      0     0             0\n",
            "45          45             Helen Lovejoy      0      0     0             0\n",
            "46          46            Jasper Beardly      0      0     0             0\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/number_pic_char.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv7P4FTCwLSh",
        "outputId": "515442a0-60f9-4a2d-a6df-b2c717cda953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Unnamed: 0                  name  total  train  test  bounding_box\n",
            "42          42           Jimbo Jones      0      0     0             0\n",
            "43          43         Bumblebee Man      0      0     0             0\n",
            "44          44          Hans Moleman      0      0     0             0\n",
            "45          45         Helen Lovejoy      0      0     0             0\n",
            "46          46        Jasper Beardly      0      0     0             0\n",
            "41          41           Lionel Hutz      3      3     0             0\n",
            "39          39             Disco Stu      8      7     1             0\n",
            "40          40          Troy Mcclure      8      7     1             0\n",
            "38          38           Miss Hoover     17     14     3             0\n",
            "36          36              Fat Tony     27     23     4             0\n",
            "37          37                   Gil     27     23     4             0\n",
            "35          35             Otto Mann     32     27     5             0\n",
            "34          34          Sideshow Mel     40     34     6             0\n",
            "33          33         Agnes Skinner     42     36     6             0\n",
            "32          32    Rainier Wolfcastle     45     38     7             0\n",
            "31          31       Cletus Spuckler     47     40     7             0\n",
            "30          30        Snake Jailbird     55     47     8             0\n",
            "29          29  Professor John Frink     65     55    10             0\n",
            "28          28         Martin Prince     71     60    11             0\n",
            "27          27         Patty Bouvier     72     61    11             0\n"
          ]
        }
      ],
      "source": [
        "#Видимо, что для некоторых персонажей информации очень мало. Посмотрим, насколько мало\n",
        "min_values = df.nsmallest(20, 'train')\n",
        "print(min_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipWfUcjp3EjM"
      },
      "source": [
        "Google Cloud рекомендует для CNN классификатора минимум 50–100 изображений на класс.\n",
        "50 - если изображения внутри класса похожи. Важно не потерять разнообразие классов, поэтому будем проводить аугментацию для всех персонажей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKSIINH6i_uq",
        "outputId": "90cd202c-c0d2-4d7d-ce48-5e0b80dd4493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Unnamed: 0                      name  total  train  test  bounding_box\n",
            "0            0             Homer Simpson   2246   1909   337           612\n",
            "1            1              Ned Flanders   1454   1236   218           595\n",
            "2            2               Moe Szyslak   1452   1234   218           215\n",
            "3            3              Lisa Simpson   1354   1151   203           562\n",
            "4            4              Bart Simpson   1342   1141   201           554\n",
            "5            5             Marge Simpson   1291   1097   194           557\n",
            "6            6          Krusty The Clown   1206   1025   181           226\n",
            "7            7         Principal Skinner   1194   1015   179           506\n",
            "8            8  Charles Montgomery Burns   1193   1014   179           650\n",
            "9            9       Milhouse Van Houten   1079    917   162           210\n",
            "10          10              Chief Wiggum    986    838   148           209\n",
            "11          11    Abraham Grampa Simpson    913    776   137           595\n",
            "12          12              Sideshow Bob    877    745   132           203\n",
            "13          13    Apu Nahasapeemapetilon    623    530    93           206\n",
            "14          14             Kent Brockman    498    423    75           213\n",
            "15          15            Comic Book Guy    469    399    70           208\n",
            "16          16            Edna Krabappel    457    388    69           212\n",
            "17          17              Nelson Muntz    358    304    54           219\n",
            "18          18             Lenny Leonard    310    264    46             0\n",
            "19          19              Mayor Quimby    246    209    37             0\n",
            "20          20           Waylon Smithers    181    154    27             0\n",
            "21          21            Maggie Simpson    128    109    19             0\n",
            "22          22      Groundskeeper Willie    121    103    18             0\n",
            "23          23             Barney Gumble    106     90    16             0\n",
            "24          24             Selma Bouvier    103     88    15             0\n",
            "25          25              Carl Carlson     98     83    15             0\n",
            "26          26              Ralph Wiggum     89     76    13             0\n",
            "27          27             Patty Bouvier     72     61    11             0\n",
            "28          28             Martin Prince     71     60    11             0\n",
            "29          29      Professor John Frink     65     55    10             0\n"
          ]
        }
      ],
      "source": [
        "# Исключаем классы, в которых менее 50 изображений\n",
        "df_filtered = df[df['train'] >= 50]\n",
        "print(df_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gQSPsyijB82",
        "outputId": "89a5aef9-2285-4a4b-a648-ed643d1e0e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "583.1333333333333\n"
          ]
        }
      ],
      "source": [
        "# Вычисляем среднее количество изображений на класс\n",
        "mean_count = df_filtered['train'].mean()\n",
        "print(mean_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9IyVSmBAkJD",
        "outputId": "c3ee6b47-efd5-40d4-8915-6ec675681455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Классы с слишком большим количеством данных: []\n",
            "Классы с оптимальным количеством данных: ['homer_simpson', 'ned_flanders', 'moe_szyslak', 'lisa_simpson', 'bart_simpson', 'marge_simpson', 'krusty_the_clown', 'principal_skinner', 'charles_montgomery_burns', 'milhouse_van_houten', 'chief_wiggum', 'abraham_grampa_simpson', 'sideshow_bob', 'apu_nahasapeemapetilon', 'kent_brockman', 'comic_book_guy', 'edna_krabappel', 'nelson_muntz', 'lenny_leonard', 'mayor_quimby', 'waylon_smithers', 'maggie_simpson', 'groundskeeper_willie', 'barney_gumble', 'selma_bouvier', 'carl_carlson', 'ralph_wiggum']\n",
            "Классы с слишком малым количеством данных: ['patty_bouvier', 'martin_prince', 'professor_john_frink']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-fe346e2fed1a>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  optimal_data = df_filtered[(df_filtered['train'] <= delta * mean_count) & (df['train'] >= mean_count / delta)]['name']\n"
          ]
        }
      ],
      "source": [
        "# Из распределения мы знаем, что у нас значительный дисбаланс классов\n",
        "# Воспользуемся правилом х delta чтобы определить слишком малые и большие классы\n",
        "\n",
        "delta = 6 #во сколько раз отличие от среднего\n",
        "\n",
        "# Разбиваем классы на группы\n",
        "# Слишком много данных (более чем в delta раз превышает среднее)\n",
        "too_many_data = df_filtered[df_filtered['train'] > delta * mean_count]['name']\n",
        "\n",
        "# Оптимальное количество данных (близко к среднему, в пределах delta)\n",
        "optimal_data = df_filtered[(df_filtered['train'] <= delta * mean_count) & (df['train'] >= mean_count / delta)]['name']\n",
        "\n",
        "# Слишком мало данных (более чем в delta раз меньше среднего)\n",
        "too_few_data = df_filtered[df_filtered['train'] < mean_count / delta]['name']\n",
        "\n",
        "\n",
        "# Преобразуем имена в нужный формат (чтобы совпадало с тем, что в папках)\n",
        "formatted_too_many_data = too_many_data.str.lower().str.replace(' ', '_')\n",
        "formatted_optimal_data = optimal_data.str.lower().str.replace(' ', '_')\n",
        "formatted_too_few_data = too_few_data.str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Результаты\n",
        "print(\"Классы с слишком большим количеством данных:\", formatted_too_many_data.tolist())\n",
        "print(\"Классы с оптимальным количеством данных:\", formatted_optimal_data.tolist())\n",
        "print(\"Классы с слишком малым количеством данных:\", formatted_too_few_data.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "G-6EUIf8wn2D"
      },
      "outputs": [],
      "source": [
        "dataset_folder = 'simpsons_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6ZcAINmElqZh"
      },
      "outputs": [],
      "source": [
        "# Преобразуем имена в нужный формат (чтобы совпадало с тем, что в папках)\n",
        "formatted_too_many_data = too_many_data.str.lower().str.replace(' ', '_')\n",
        "formatted_optimal_data = optimal_data.str.lower().str.replace(' ', '_')\n",
        "formatted_too_few_data = too_few_data.str.lower().str.replace(' ', '_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFQxVbmww7Uc",
        "outputId": "77c76593-2120-4de7-df75-c9f78784e2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество изображений: 20582\n",
            "Количество меток: 20582\n",
            "Пример изображения: simpsons_dataset/homer_simpson/pic_1166.jpg\n",
            "Пример метки: homer_simpson\n"
          ]
        }
      ],
      "source": [
        "# Разделение на images и labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Перебираем папки и собираем изображения и метки\n",
        "for character in pd.concat([formatted_optimal_data, formatted_too_few_data]):\n",
        "    character_folder_path = os.path.join(dataset_folder, character)\n",
        "    if os.path.exists(character_folder_path):\n",
        "        for file_name in os.listdir(character_folder_path):\n",
        "            file_path = os.path.join(character_folder_path, file_name)\n",
        "            if os.path.isfile(file_path):\n",
        "                images.append(file_path)\n",
        "                labels.append(character)\n",
        "\n",
        "# Проверяем результаты разделения на images и labels\n",
        "print(f'Количество изображений: {len(images)}')\n",
        "print(f'Количество меток: {len(labels)}')\n",
        "print(f'Пример изображения: {images[0] if images else \"Нет изображений\"}')\n",
        "print(f'Пример метки: {labels[0] if labels else \"Нет меток\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8KgUVMDzjAd"
      },
      "source": [
        "# 3. Аугментация данных\n",
        "Генерируем доп изображения в малые классы, чтобы скорректировать дисбаланс классов.\n",
        "\n",
        "Что подойдет:\n",
        "- Небольшое изменение масштаба, сдивиги, поворот\n",
        "\n",
        "\n",
        "Что не подойдет:\n",
        "- Ротация на 90 градусов и более\n",
        "- Сильная обрезка изображений, фрагментирование портретов\n",
        "- Изменение цвета для мультка со узнаваемой цветовой схемой это может быть фатально\n",
        "- Сильный шум или размытие не характерны для скриншотов из мультика — такие методы скорее подойдут для фото из реальной жизни\n",
        "\n",
        "Аугментацию можно проводить как отдельно, так и на лету (онлайн), прямо во время обучения модели, с использованием тех же библиотек tensorflow или аналогов.\n",
        "\n",
        "Оставлю пример кода как для отедльной, так и для онлайновой аугментации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nfFnanjDz9Rg"
      },
      "outputs": [],
      "source": [
        "# Настройка параметров генерации изображений\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255, #чтобы привести значение пикселя к от 0 до 1 (так лучше для модели)\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "augmentation_counts = {}  # Для отслеживания количества сгенерированных изображений для каждого класса\n",
        "augmented_image_paths = []  # Для хранения путей к сгенерированным изображениям\n",
        "\n",
        "augmented_dataset_folder = \"augmented_dataset\"  # Папка для сохранения сгенерированных изображений\n",
        "os.makedirs(augmented_dataset_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_EGsR0K5IttJ"
      },
      "outputs": [],
      "source": [
        "# Аугментация для классов с недостаточным количеством данных\n",
        "for character in formatted_too_few_data:\n",
        "    character_folder_path = os.path.join(dataset_folder, character)\n",
        "    augmented_character_folder_path = os.path.join(augmented_dataset_folder, character)\n",
        "    os.makedirs(augmented_character_folder_path, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(character_folder_path):\n",
        "        current_count = len(os.listdir(character_folder_path))\n",
        "        target_count = int(mean_count)  # Целевое количество изображений для каждого класса = среднее\n",
        "        images_needed = target_count - current_count\n",
        "        augmentation_counts[character] = 0\n",
        "\n",
        "        if images_needed > 0:\n",
        "            for file_name in os.listdir(character_folder_path):\n",
        "                file_path = os.path.join(character_folder_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    # Проверка существования файла и корректности пути\n",
        "                    if not os.path.exists(file_path):\n",
        "                        print(f\"Ошибка: файл {file_path} не существует.\")\n",
        "                        continue\n",
        "                    try:\n",
        "                        # Чтение изображения\n",
        "                        img = cv2.imread(file_path)\n",
        "                        if img is None:\n",
        "                            print(f\"Ошибка: не удалось прочитать изображение {file_path}.\")\n",
        "                            continue\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                        img = cv2.resize(img, (64, 64))  # Приводим к единому размеру\n",
        "                         # Применение аугментации\n",
        "                        img = img.reshape((1,) + img.shape)  # Преобразуем для генератора\n",
        "                        i = 0\n",
        "                        for batch in datagen.flow(img, batch_size=1):\n",
        "                            augmented_img = (batch[0] * 255).astype(np.uint8)  # Преобразуем обратно в изображение\n",
        "                            save_path = os.path.join(augmented_character_folder_path, f\"augmented_{file_name.split('.')[0]}_{i}.jpg\")\n",
        "                            cv2.imwrite(save_path, cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR))\n",
        "                            augmented_images.append(save_path)\n",
        "                            augmented_labels.append(character)\n",
        "                            augmentation_counts[character] += 1\n",
        "                            augmented_image_paths.append(save_path)\n",
        "                            i += 1\n",
        "                            if i >= images_needed:  # Ограничение на количество сгенерированных изображений для достижения целевого количества\n",
        "                                break\n",
        "                        if augmentation_counts[character] >= images_needed:\n",
        "                            break\n",
        "                    except Exception as e:\n",
        "                        print(f\"Ошибка при обработке файла {file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgLiqx0VH-29",
        "outputId": "36df944d-c8e7-4635-f2af-26e91ebca73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Класс  Количество сгенерированных изображений\n",
            "0         patty_bouvier                                     306\n",
            "1         martin_prince                                     307\n",
            "2  professor_john_frink                                     313\n"
          ]
        }
      ],
      "source": [
        "# Таблица с количеством сгенерированных изображений для каждого класса\n",
        "augmentation_df = pd.DataFrame(list(augmentation_counts.items()), columns=['Класс', 'Количество сгенерированных изображений'])\n",
        "print(augmentation_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UjbP48LGsL2",
        "outputId": "d0b2f606-329d-4ece-b71a-6d583896234c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Общее количество изображений после аугментации: 21508\n",
            "Общее количество меток после аугментации: 21508\n"
          ]
        }
      ],
      "source": [
        "# Теперь можно объединить оригинальные и аугментированные изображения и метки\n",
        "images.extend(augmented_images)\n",
        "labels.extend(augmented_labels)\n",
        "\n",
        "print(f'Общее количество изображений после аугментации: {len(images)}')\n",
        "print(f'Общее количество меток после аугментации: {len(labels)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4mhHckc1AA1"
      },
      "source": [
        "# 4. Создание модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eay7awmJmdmw"
      },
      "outputs": [],
      "source": [
        "# Разделение на тренировочный и тестовый наборы\n",
        "data = pd.DataFrame({'image': images, 'label': labels})\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['image'].tolist(), data['label'].tolist(), test_size=0.2, stratify=data['label'], random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zBL2mJmRLjWd"
      },
      "outputs": [],
      "source": [
        "# Подготовка данных для модели\n",
        "filtered_X_train = []\n",
        "filtered_y_train = []\n",
        "for img_path, label in zip(X_train, y_train):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (64, 64)) #поискать другой трансформер для пред процессинга\n",
        "        filtered_X_train.append(img)\n",
        "        filtered_y_train.append(label)\n",
        "X_train_images = np.array(filtered_X_train) / 255.0  # Нормализация\n",
        "\n",
        "filtered_X_test = []\n",
        "filtered_y_test = []\n",
        "for img_path, label in zip(X_test, y_test):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "        filtered_X_test.append(img)\n",
        "        filtered_y_test.append(label)\n",
        "X_test_images = np.array(filtered_X_test) / 255.0  # Нормализация\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WMj8gp5gfFGb"
      },
      "outputs": [],
      "source": [
        "# Преобразование меток в категориальный вид\n",
        "label_mapping = {label: idx for idx, label in enumerate(data['label'].unique())}\n",
        "filtered_y_train = np.array([label_mapping[label] for label in filtered_y_train])\n",
        "filtered_y_test = np.array([label_mapping[label] for label in filtered_y_test])\n",
        "y_train = to_categorical(filtered_y_train, num_classes=len(label_mapping))\n",
        "y_test = to_categorical(filtered_y_test, num_classes=len(label_mapping))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FRvHRWr1I_0",
        "outputId": "0273382f-6177-4a4b-f02a-0029c287d3a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Создание модели\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(label_mapping), activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lckwCEpXOSQd"
      },
      "source": [
        "Softmax — ф-я для преобразования вектора реальных чисел в вероятностное распределение. Подходит для задач многоклассовой классификации входных данных.\n",
        "\n",
        "Преобразует каждый элемент входного вектора в значение от 0 до 1, причем сумма всех выходных значений равна 1. Это позволяет интерпретировать выходные данные как вероятности принадлежности к каждому из классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBYLorsZ3LI_"
      },
      "source": [
        "# 5. Компиляция и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VH6sIv2j3NNS"
      },
      "outputs": [],
      "source": [
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUiCmnSkQKsf"
      },
      "source": [
        "Категориальная кросс-энтропия — это функция потерь, используемая в задачах многоклассовой классификации, где модель должна предсказать вероятность принадлежности примера к одной из нескольких категорий.\n",
        "\n",
        "Измеряет разницу между истинным распределением вероятностей (обычно закодированным в формате one-hot) и предсказанным распределением вероятностей, полученным от модели (обычно через softmax)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOpelHNL3bb-",
        "outputId": "7923dd0c-1f4a-484e-b749-3747f9254139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 175ms/step - accuracy: 0.1943 - loss: 2.8680 - val_accuracy: 0.5132 - val_loss: 1.8032\n",
            "Epoch 2/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 179ms/step - accuracy: 0.4642 - loss: 1.9172 - val_accuracy: 0.5979 - val_loss: 1.4625\n",
            "Epoch 3/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 180ms/step - accuracy: 0.5589 - loss: 1.5264 - val_accuracy: 0.6574 - val_loss: 1.2492\n",
            "Epoch 4/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 177ms/step - accuracy: 0.6378 - loss: 1.2523 - val_accuracy: 0.7073 - val_loss: 1.0793\n",
            "Epoch 5/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 179ms/step - accuracy: 0.6942 - loss: 1.0356 - val_accuracy: 0.7197 - val_loss: 1.0233\n",
            "Epoch 6/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 174ms/step - accuracy: 0.7349 - loss: 0.8687 - val_accuracy: 0.7262 - val_loss: 0.9854\n",
            "Epoch 7/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 174ms/step - accuracy: 0.7729 - loss: 0.7321 - val_accuracy: 0.7417 - val_loss: 0.9480\n",
            "Epoch 8/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 175ms/step - accuracy: 0.8006 - loss: 0.6314 - val_accuracy: 0.7538 - val_loss: 0.9335\n",
            "Epoch 9/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 179ms/step - accuracy: 0.8252 - loss: 0.5356 - val_accuracy: 0.7585 - val_loss: 0.9335\n",
            "Epoch 10/10\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 178ms/step - accuracy: 0.8430 - loss: 0.4761 - val_accuracy: 0.7506 - val_loss: 0.9667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b15a8f01a80>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Обучение модели\n",
        "model.fit(X_train_images, y_train, validation_data=(X_test_images, y_test), epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOFQiq_mUdMa",
        "outputId": "11151653-6bd6-4ee4-aba3-8245c2ffeea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "           homer_simpson       0.64      0.77      0.70       449\n",
            "            ned_flanders       0.77      0.84      0.80       291\n",
            "             moe_szyslak       0.60      0.84      0.70       290\n",
            "            lisa_simpson       0.63      0.54      0.58       271\n",
            "            bart_simpson       0.57      0.59      0.58       268\n",
            "           marge_simpson       0.88      0.90      0.89       258\n",
            "        krusty_the_clown       0.84      0.90      0.87       241\n",
            "       principal_skinner       0.78      0.76      0.77       239\n",
            "charles_montgomery_burns       0.68      0.67      0.67       239\n",
            "     milhouse_van_houten       0.83      0.86      0.85       216\n",
            "            chief_wiggum       0.77      0.85      0.81       197\n",
            "  abraham_grampa_simpson       0.83      0.68      0.75       183\n",
            "            sideshow_bob       0.91      0.86      0.88       175\n",
            "  apu_nahasapeemapetilon       0.88      0.90      0.89       125\n",
            "           kent_brockman       0.83      0.86      0.84       100\n",
            "          comic_book_guy       0.80      0.72      0.76        94\n",
            "          edna_krabappel       0.80      0.66      0.72        91\n",
            "            nelson_muntz       0.75      0.33      0.46        72\n",
            "           lenny_leonard       0.89      0.52      0.65        62\n",
            "            mayor_quimby       0.82      0.55      0.66        49\n",
            "         waylon_smithers       0.80      0.44      0.57        36\n",
            "          maggie_simpson       1.00      0.23      0.38        26\n",
            "    groundskeeper_willie       0.70      0.67      0.68        24\n",
            "           barney_gumble       0.80      0.19      0.31        21\n",
            "           selma_bouvier       0.92      0.60      0.73        20\n",
            "            carl_carlson       1.00      0.32      0.48        19\n",
            "            ralph_wiggum       0.50      0.17      0.25        18\n",
            "           patty_bouvier       0.95      0.95      0.95        76\n",
            "           martin_prince       0.99      0.87      0.92        76\n",
            "    professor_john_frink       0.95      0.83      0.89        76\n",
            "\n",
            "                accuracy                           0.75      4302\n",
            "               macro avg       0.80      0.66      0.70      4302\n",
            "            weighted avg       0.76      0.75      0.75      4302\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Оценка модели и метрики\n",
        "y_pred = model.predict(X_test_images)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Вывод отчета по метрикам классификации\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=list(label_mapping.keys()))\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHLDzx5BSQm_"
      },
      "source": [
        "Precision — показывает, насколько точно модель предсказывает положительные классы. Если модель классифицирует кадры с Гомером Симпсоном, и она предсказывает 10 кадров как \"Гомер\", но только 8 из них действительно являются Гомером, то precision будет равен 80%.\n",
        "\n",
        "\n",
        "Recall — это метрика, которая показывает, насколько хорошо модель находит все истинные положительные примеры. Если в наборе данных есть 15 кадров с Гомером, а модель правильно классифицировала только 8 из них, то recall будет равен 53% (8 истинных положительных из 15 фактических положительных).\n",
        "\n",
        "\n",
        "F1-score — это гармоническое среднее между precision и recall. Он позволяет объединить обе метрики в одну и дает более полное представление о производительности модели. Использование F1-score полезно в ситуациях с несбалансированными классами, когда важно учитывать как точность, так и полноту.\n",
        "\n",
        "Support — это просто количество истинных экземпляров для каждого класса в тестовом наборе данных. Показывает, сколько тестовых примеров есть в каждом классе и помогает понять распределение классов в данных.\n",
        "\n",
        "Лосс (или функция потерь) — это мера, которая показывает, насколько хорошо или плохо модель предсказывает результаты по сравнению с фактическими значениями. Она используется для оценки качества модели во время обучения и оптимизации. Лосс помогает алгоритму понять, насколько далеко его предсказания от истинных значений, и на основании этого корректировать свои параметры. Используется в процессе обучения, тогда как метрики — оценивают его итог."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
